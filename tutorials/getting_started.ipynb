{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with LUQ\n",
    "\n",
    "Welcome to the LUQ introductory tutorial!\n",
    "\n",
    "Large Language Models (LLMs) **can sometimes hallucinate** — generating responses that sound plausible but are actually incorrect. One effective way to mitigate this issue is by measuring **how uncertain an LLM** is about its answers. The greater the uncertainty, the higher the likelihood that the response may be a hallucination.\n",
    "\n",
    "But **how can we easily measure an LLM's uncertainty** for a given question?\n",
    "\n",
    "That's where LUQ comes in. LUQ is a Python package specifically designed to quantify uncertainty in LLM-generated responses.\n",
    "\n",
    "Follow along to learn how easy it is to bring uncertainty quantification into your own projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install LUQ and Import Required Methods\n",
    "\n",
    "To get started, install the LUQ package and import the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install luq==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import luq\n",
    "from luq.models import MaxProbabilityEstimator\n",
    "from luq.llm import HFLLMWrapper\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define an LLM\n",
    "\n",
    "LUQ provides convenient abstractions for working with Hugging Face and other popular LLM providers, so you can easily plug in your model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrap the LLM and Generate Samples\n",
    "\n",
    "To use LUQ's uncertainty quantification features, you need to wrap your LLM with `HFLLMWrapper` (or the appropriate wrapper for your model type). This enables LUQ to generate multiple samples from the model for a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HFLLMWrapper(tokenizer=tokenizer, model=model)\n",
    "samples = luq.llm.generate_n_samples_and_answer(\n",
    "    llm,\n",
    "    prompt=\"A, B, C, or D\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Estimate Uncertainty (The Fun Part!)\n",
    "\n",
    "Now that you've generated multiple samples, it's time to quantify uncertainty using LUQ's built-in methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_estimator = MaxProbabilityEstimator()\n",
    "print(mp_estimator.estimate_uncertainty(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: You're Ready to Go!\n",
    "\n",
    "That's it — you're now equipped to start experimenting with uncertainty quantification in your own projects using LUQ!\n",
    "\n",
    "Whether you're building more robust AI systems, analyzing model behavior, or just exploring how confident your LLM is, LUQ gives you the tools to dive deeper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
