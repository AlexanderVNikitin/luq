{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98fec8f4",
   "metadata": {},
   "source": [
    "# Working with LUQ Datasets\n",
    "\n",
    "Welcome to LUQ datasets tutorials. The aim of this tutorial is to provide guidance on creating your own datasets and use some of the pre-existing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29fca7",
   "metadata": {},
   "source": [
    "## Step 1. Preprocess the dataset.\n",
    "\n",
    "In order to unify the work with different QA datasets luq requires the user to pre-process the existing dataset into luq format. The required format is straightforward:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"question\": \"Is this an example of a question?\"â€š\n",
    "            \"answer\": \"Yes, it is\",\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "There is a script that provide pre-processing for many existing datasets, such as CoQA, NQ, and others in `scripts/process_dataset.py`.\n",
    "\n",
    "Let's for simplicity show it on CoQA processing example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d1f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir data/coqa\n",
    "!python scripts/process_datasets.py \\\n",
    "    --dataset=coqa \\\n",
    "    --output=data/coqa/processed.json"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
